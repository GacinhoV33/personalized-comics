{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgwwvpVpSs9"
      },
      "source": [
        "## Story Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA53HXUNpufF"
      },
      "source": [
        "**Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu6Ar47sptjk"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K5EcGtIqmsu"
      },
      "source": [
        "**Conecct with OpenAI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ_Vsr4qqzD1"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "API_KEY = 'PROVIDE_OPENAI_API_KEY_THERE'\n",
        "# API_KEY = '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'\n",
        "openai.api_key = API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy4ikr0Dq7k1"
      },
      "source": [
        "**Information about main character of story**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DirfErOarBbV"
      },
      "outputs": [],
      "source": [
        "#@markdown Name of the main character.\n",
        "NAME = \"Olaf\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Age\n",
        "AGE = \"23\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Super Power.\n",
        "SUPER_POWER = \"He is the fastest person on the world\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Story line concept\n",
        "STORY = \"During the day, Olaf is programmer in Google. In the night he is super-hero that saves small kids.  He is fighting with dragons and aliens\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Personal informations.\n",
        "PERSONAL_INFO = \"Olaf is creative and he don't like bananas. He used to attend a ninja school\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Motive - it can be funny, scary, serious etc.\n",
        "MOTIVE = \"Funny and creative\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Style of photos. Examples: \"drawing style\", \"van gogh style\", \"futuristic style\", \"digital art\", \"realistic style\"\n",
        "STYLE_NAME = \"digital art\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown Language (Polish or English).\n",
        "LANGUAGE = \"English\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfT4JlzFx2el"
      },
      "outputs": [],
      "source": [
        "LANGUAGE = \"Polish\" if LANGUAGE == \"Polish\" else \"English\"\n",
        "describtion = f\"Create a comic about my friend {NAME} that has around 12 pannels. His age is {AGE} and his super power is: {SUPER_POWER}. There are some information that could be used in story: {STORY}. There is also some personal information about {NAME}: {PERSONAL_INFO}. Try to be {MOTIVE} and do it in {LANGUAGE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm2btyQ4Pzg9"
      },
      "outputs": [],
      "source": [
        "describtion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBIEy3gFpfcN"
      },
      "outputs": [],
      "source": [
        "TEMPERATURE = 0.5\n",
        "MAX_TOKENS = 3900\n",
        "FREQUENCY_PENALTY = 0.05\n",
        "PRESENCE_PENALTY = 0.05\n",
        "\n",
        "\n",
        "def make_open_AI_request(desc: str, MAX_TOKENS=MAX_TOKENS) -> str:\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=desc,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        top_p=1,\n",
        "        frequency_penalty=FREQUENCY_PENALTY,\n",
        "        presence_penalty=PRESENCE_PENALTY,\n",
        "    )\n",
        "    return response['choices'][0]['text']\n",
        "\n",
        "\n",
        "def divide_story_into_pannels(story: str) -> list:\n",
        "  \"\"\"Function that divides pannels returned from OpenAI request into individual pannels\"\"\"\n",
        "  separated_pannels = story.split(\"\\n\\nPanel\")\n",
        "  separated_pannels.pop(0)\n",
        "  for i, panel in enumerate(separated_pannels):\n",
        "    panel_splitted = panel.split(\"\\n\")\n",
        "    separated_pannels[i] = panel_splitted[-1]\n",
        "\n",
        "  return separated_pannels\n",
        "\n",
        "def pretty_prompts(prompts: str) -> list:\n",
        "  \"\"\"Function that clear prompts from unneccessary signs like , . \\n \"\"\"\n",
        "  prompt_list = prompts.split(\"\\nPanel\")\n",
        "  prompt_list.pop(0)\n",
        "  prompt_list_cleared = [prompt[4:].replace(\".\", \"\") for prompt in prompt_list]\n",
        "  return prompt_list_cleared\n",
        "\n",
        "def clear_panels(panels: list, word: str):\n",
        "    return [panel.replace(word, '')[1:] for panel in panels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gra1VN1g0dwU"
      },
      "source": [
        "**Chat-GPT response and text preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR5zbruqz-Rg"
      },
      "outputs": [],
      "source": [
        "story: str = make_open_AI_request(describtion)\n",
        "panels: list = divide_story_into_pannels(story)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Generated story: {story}\")\n",
        "print(f\"Panels created from story: {panels}\")"
      ],
      "metadata": {
        "id": "yCkb6q226Qmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WzJ5MNEeYJe"
      },
      "outputs": [],
      "source": [
        "# panels = clear_panels(panels, \"Caption:\") # use when caption appear in OpenAI response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxG13bRycYUa"
      },
      "outputs": [],
      "source": [
        "\"\"\"This request is responsible for getting prompts for each pannel that will work well with Stable Diffusion model.\n",
        "It's worth to notice that prompts returned by OpenAI are very bad compared to prompts generated by human.\n",
        "It's recommended to generate promps manually.\n",
        "\"\"\"\n",
        "second_req = f\"For each pannel generate good prompt with max 4 words that I can use in stable diffusion model to generate an ilustration: {story}\"\n",
        "prompts_OpenAI = make_open_AI_request(second_req, 2000)\n",
        "print(prompts_OpenAI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukgZPh-cc90u"
      },
      "outputs": [],
      "source": [
        "prompts_OpenAI = pretty_prompts(prompts_OpenAI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69wIUVUbpZ5m"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EU9IUsZ1BoM"
      },
      "outputs": [],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5DEf5gy1FRM"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpPUxoYf1HWY"
      },
      "outputs": [],
      "source": [
        "#@title Login to HuggingFace ðŸ¤—\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "# https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJJCUYs01abD"
      },
      "outputs": [],
      "source": [
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown Name/Path of the initial model.\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "# MODEL_NAME = \"/content/drive/MyDrive/stable_diffusion_weights/Olaf\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the directory name to save model at.\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion_weights/Daniel_FINAL\" #@param {type:\"string\"}\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB46jx5-1mAE"
      },
      "source": [
        "\n",
        "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaktTdvR1ppU"
      },
      "source": [
        "Add `--gradient_checkpointing` flag for around 9.92 GB VRAM usage.\n",
        "\n",
        "remove `--use_8bit_adam` flag for full precision. Requires 15.79 GB with `--gradient_checkpointing` else 17.8 GB.\n",
        "\n",
        "remove `--train_text_encoder` flag to reduce memory usage further, degrades output quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ih2hNET1lF5"
      },
      "outputs": [],
      "source": [
        "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "TOKEN_NAME = \"zkjw\" #@param {type: \"string\"}\n",
        "concepts_list = [\n",
        "    # {\n",
        "    #     \"instance_prompt\":      \"photo of zwx dog\",\n",
        "    #     \"class_prompt\":         \"photo of a dog\",\n",
        "    #     \"instance_data_dir\":    \"/content/data/zwx\",\n",
        "    #     \"class_data_dir\":       \"/content/data/dog\"\n",
        "    # },\n",
        "    {\n",
        "        \"instance_prompt\":      f\"photo of {TOKEN_NAME} person\",\n",
        "        \"class_prompt\":         \"photo of a person\",\n",
        "        \"instance_data_dir\":    f\"/content/data/{TOKEN_NAME}\",\n",
        "        \"class_data_dir\":       \"/content/data/person\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrubfbdGniX3"
      },
      "source": [
        "**Upload photos to google drive**\n",
        "\n",
        " Remember that photos needs to have 512x512 resolution. This link enable achieving this in fast way https://www.birme.net/?target_width=512&target_height=512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7seyGxc2kHE"
      },
      "outputs": [],
      "source": [
        "#@markdown Upload your images by running this cell.\n",
        "\n",
        "#@markdown OR\n",
        "\n",
        "#@markdown You can use the file manager on the left panel to upload (drag and drop) to each `instance_data_dir` (it uploads faster). You can also upload your own class images in `class_data_dir` if u don't wanna generate with SD.\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUF4K6nY2lnE"
      },
      "outputs": [],
      "source": [
        "!python3 train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"fp16\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=2 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1.5e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=10 \\\n",
        "  --num_class_images=300 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=900 \\\n",
        "  --save_interval=150 \\\n",
        "  --save_sample_prompt=f\"{TOKEN_NAME} sit on the cloud\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
        "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH2-RMz12s5k"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = \"/content/drive/MyDrive/stable_diffusion_weights/Daniel_FINAL/900\" #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gueHBny42wiI"
      },
      "outputs": [],
      "source": [
        "#@markdown Run to generate a grid of preview images from the last saved weights.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ASwctl121uA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFu0WyUp232r"
      },
      "outputs": [],
      "source": [
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 52362 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "1Mg-U5GU2-y5"
      },
      "outputs": [],
      "source": [
        "#@title Run for generating images.\n",
        "\n",
        "prompt = \"zkjw stands on the Mars, shoe above them\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "num_samples = 5 #@param {type:\"number\"}\n",
        "guidance_scale = 7 #@param {type:\"number\"}\n",
        "num_inference_steps = 32 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLvAkOLgNEUv"
      },
      "source": [
        "- Good prompts: digital art -> cool photos for comic\n",
        "- Overfitted models works good for digital art"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGmKGefw3EmD"
      },
      "source": [
        "# Comic generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoX6uGaPqXl5"
      },
      "source": [
        "##**Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDUbPLYmCEa8"
      },
      "outputs": [],
      "source": [
        "from numpy.ma import size\n",
        "import re\n",
        "import spacy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw, ImageFont\n",
        "\n",
        "NUM_OF_PHOTOS: int = 4\n",
        "NUM_INFERENCE_STEPS: int = 36\n",
        "\n",
        "def create_photos(prompt: str, prompt_AI: str,negative_prompt: str = \"\", num_of_photos: int = NUM_OF_PHOTOS, num_inference_steps: int = NUM_INFERENCE_STEPS) -> list:\n",
        "  num_samples = num_of_photos\n",
        "  guidance_scale = 7.5\n",
        "  height = 512\n",
        "  width = 512\n",
        "  with autocast(\"cuda\"), torch.inference_mode():\n",
        "      images = pipe(\n",
        "          # prompt,\n",
        "          prompt_AI,\n",
        "          height=height,\n",
        "          width=width,\n",
        "          negative_prompt=negative_prompt,\n",
        "          num_images_per_prompt=num_samples,\n",
        "          num_inference_steps=num_inference_steps,\n",
        "          guidance_scale=guidance_scale,\n",
        "          generator=g_cuda\n",
        "      ).images\n",
        "\n",
        "  return images\n",
        "\n",
        "\n",
        "def replace_and_add_tokens(prompt: str) -> tuple:\n",
        "  re.sub(r'[^\\w]', ' ', prompt)\n",
        "  split_prompt = prompt.split(\" \")\n",
        "  for i, word in enumerate(split_prompt):\n",
        "    if word == NAME:\n",
        "      split_prompt[i] = TOKEN_NAME\n",
        "  return \" \".join(split_prompt), prompt\n",
        "\n",
        "ILUSTRATION_WIDTH = 512\n",
        "ILUSTRATION_HEIGHT = 712\n",
        "\n",
        "def chunk_it(seq, num):\n",
        "    avg = len(seq) / float(num)\n",
        "    out = []\n",
        "    last = 0.0\n",
        "\n",
        "    while last < len(seq):\n",
        "        out.append(seq[int(last):int(last + avg)])\n",
        "        last += avg\n",
        "\n",
        "    return out\n",
        "\n",
        "def find_longest_pannel(list_of_pannels: list) -> list:\n",
        "  list_of_words = [\" \".join(pannel) for pannel in list_of_pannels]\n",
        "  max_width: int = -1\n",
        "  idx: int = 0\n",
        "  img = Image.fromarray((np.zeros((height, width, 3))).astype('uint8'), 'RGB')\n",
        "  draw = ImageDraw.Draw(img)\n",
        "  font = ImageFont.truetype(\"/content/drive/MyDrive/stable_diffusion_weights/Sunlit_Memories.ttf\", 25)  # Podaj nazwÄ™ czcionki i rozmiar\n",
        "  for i, word in enumerate(list_of_words):\n",
        "    text_width, text_height = draw.textsize(word, font=font)\n",
        "    if text_width > max_width:\n",
        "      max_width = text_width\n",
        "      idx = i\n",
        "  return list_of_words[idx]\n",
        "\n",
        "def create_text_photo(pannel: str):\n",
        "  text_color = (233, 233, 230)\n",
        "  width, height = ILUSTRATION_WIDTH, ILUSTRATION_HEIGHT - 512\n",
        "  img = Image.fromarray((np.zeros((height, width, 3))).astype('uint8'), 'RGB')\n",
        "  draw = ImageDraw.Draw(img)\n",
        "  # drawing\n",
        "  pannel_length = int(len(pannel) / 3)\n",
        "  pannel_split = pannel.split(\" \")\n",
        "  # pannel_split_length = len(pannel_split)\n",
        "\n",
        "  chunked_pannel = chunk_it(pannel_split, 3)\n",
        "\n",
        "  draw.rectangle([(0, 0), (width, height)])\n",
        "\n",
        "\n",
        "\n",
        "  longest_pannel = \" \".join(find_longest_pannel(chunked_pannel))\n",
        "  font_size = 55\n",
        "  font = ImageFont.truetype(\"/content/drive/MyDrive/stable_diffusion_weights/Sunlit_Memories.ttf\", font_size)  # Podaj nazwÄ™ czcionki i rozmiar\n",
        "  text_width, text_height = draw.textsize(longest_pannel, font=font)\n",
        "\n",
        "  while text_width > width or text_height > height:\n",
        "    font_size -= 1\n",
        "    font = ImageFont.truetype(\"/content/drive/MyDrive/stable_diffusion_weights/Sunlit_Memories.ttf\", font_size)\n",
        "    # text_width, text_height = draw.textsize(pannel[0: pannel_length+5], font=font)\n",
        "    text_width, text_height = draw.textsize(longest_pannel, font=font)\n",
        "\n",
        "  for i in range(3):\n",
        "    text = \" \".join(chunked_pannel[i])\n",
        "    draw.text((10, i * (font_size + 3) + 10), text, fill=text_color, font=font)\n",
        "\n",
        "  return img\n",
        "\n",
        "def create_ilustration(photo, pannel: str, save_photo: bool = False) -> list:\n",
        "  ilustration = np.zeros((ILUSTRATION_HEIGHT, ILUSTRATION_WIDTH, 3))\n",
        "  text_photo = create_text_photo(pannel)\n",
        "\n",
        "  ilustration[0:512, 0:512, :] = photo\n",
        "  ilustration[512:ILUSTRATION_HEIGHT, 0:ILUSTRATION_WIDTH, :] = text_photo\n",
        "  # Konwertuj tablicÄ™ NumPy na obiekt Image\n",
        "  img = Image.fromarray((ilustration).astype('uint8'), 'RGB')\n",
        "\n",
        "  # saving\n",
        "  if(save_photo):\n",
        "    img.save(\"photo.jpg\")\n",
        "  return img\n",
        "\n",
        "def convert_AI_prompt(prompt: str) -> tuple:\n",
        "  words = [item.lower() for item in prompt.split(\" \")]\n",
        "  \"\"\"If there is a name of hero in prompt we replace it with token and leave as it is\"\"\"\n",
        "  if NAME.lower() in words:\n",
        "    is_prompt_with_name: bool = True\n",
        "    return prompt.replace(NAME, TOKEN_NAME, 1) + f\", {STYLE_NAME}\", is_prompt_with_name, \"\"\n",
        "  else:\n",
        "    \"\"\" In this case we may generate photo without our hero. Sometimes it's okay, sometimes it's not. \"\"\"\n",
        "    \"\"\" We will create 2 photos of exact prompt and 3 photos with token added \"\"\"\n",
        "    is_prompt_with_name: bool = False\n",
        "    return f\"{prompt}, {STYLE_NAME}\", is_prompt_with_name, f\"{TOKEN_NAME} {prompt}, {STYLE_NAME}\"\n",
        "\n",
        "def create_ilustrations_for_pannel(pannel: str, prompt_OpenAI: str) -> list:\n",
        "  prompt, prompt_org = replace_and_add_tokens(pannel)\n",
        "  prompt_AI, name_flag, prompt_modified = convert_AI_prompt(prompt_OpenAI)\n",
        "  if name_flag:\n",
        "    photos = create_photos(prompt, prompt_AI, num_of_photos=NUM_OF_PHOTOS)\n",
        "    ilustrations = [create_ilustration(photo, prompt_org) for photo in photos]\n",
        "  else:\n",
        "    photos_without_name = create_photos(prompt, prompt_AI, num_of_photos=2)\n",
        "    photos_with_name = create_photos(prompt, prompt_AI, num_of_photos=NUM_OF_PHOTOS - 2)\n",
        "    photos = [*photos_without_name, *photos_with_name]\n",
        "    ilustrations = [create_ilustration(photo, prompt_org) for photo in photos]\n",
        "  return ilustrations\n",
        "\n",
        "def create_comic_array():\n",
        "  comic_list: list = list()\n",
        "  for pannel, prompt in zip(panels, prompts_OpenAI):\n",
        "    print(f\"Pannel: {pannel}\")\n",
        "    comic_list.append(create_ilustrations_for_pannel(pannel, prompt))\n",
        "  return comic_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHZJwTfp2Zi"
      },
      "source": [
        "## Creating and displaying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxWgTLmlZ7Vb"
      },
      "outputs": [],
      "source": [
        "comic_list = create_comic_array()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8vKo0B-byff"
      },
      "outputs": [],
      "source": [
        "for ilustrations in comic_list:\n",
        "  display(ilustrations[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6Qt4jDMjxPY"
      },
      "source": [
        "**Create ilustrations with fine-tunned model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgefA7oC3H98"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "pannel_photos: list = list()\n",
        "for pannel in panels:\n",
        "  photos = create_photos_for_pannel(pannel)\n",
        "  pannel_photos.append(random.choice(photos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8Frno2CjHfU"
      },
      "source": [
        "## Semi-Automatic comic generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "043HLZAbwqfw"
      },
      "outputs": [],
      "source": [
        "# RUN THIS FOR PROPER SAVING/DISPLAYING\n",
        "FOLDER_TITLE: str = \"Olaf_story2\"\n",
        "save_folder: str = f'/content/drive/MyDrive/{FOLDER_TITLE}'\n",
        "NUM_OF_PHOTOS: int = 4\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import display\n",
        "\n",
        "if not os.path.exists(save_folder):\n",
        "  os.mkdir(save_folder)\n",
        "\n",
        "def save_photos(photos: list, pannel_number: int):\n",
        "  for i, photo in enumerate(photos):\n",
        "    save_path = save_folder + f'/pannel{pannel_number}/photo{i}.png'\n",
        "    photo.save(save_path)\n",
        "\n",
        "def show_photos(pannel_number: int):\n",
        "  save_path = save_folder + f'/pannel{pannel_number}/'\n",
        "  fig, axes = plt.subplots(1, num_of_photos, figsize=(16, num_of_photos * 16) ,gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "  print(os.listdir(save_path))\n",
        "  for i, photo_path in enumerate(os.listdir(save_path)):\n",
        "    img = mpimg.imread(os.path.join(save_path, photo_path))\n",
        "    currAxes = axes[i]\n",
        "    currAxes.set_title(f\"Image {i}\")\n",
        "    currAxes.axis('off')\n",
        "    currAxes.imshow(img, cmap='gray')\n",
        "    # plt.show()\n",
        "  plt.tight_layout()\n",
        "  display(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bau15GWhjo4b"
      },
      "outputs": [],
      "source": [
        "# 1. Prompt change: type 'YES' for change, and then write your own, otherwise write anything else\n",
        "CHANGE_PROMPT_FEATURE: bool = True\n",
        "final_ilustrations: list = list()\n",
        "\n",
        "for pannel_number, (pannel, prompt) in enumerate(zip(panels, prompts_OpenAI)):\n",
        "  pannel_path = save_folder + f'/pannel{pannel_number}'\n",
        "  if not os.path.exists(pannel_path):\n",
        "    os.mkdir(pannel_path)\n",
        "  print(f\"Panel: {pannel}\")\n",
        "  print(f\"Prompt: {prompt}\")\n",
        "  if CHANGE_PROMPT_FEATURE:\n",
        "    # change_prompt = input(\"Do you want change prompt?\")\n",
        "    prompt = input(\"New prompt: \")\n",
        "  photos = create_ilustrations_for_pannel(pannel, prompt)\n",
        "  save_photos(photos, pannel_number)\n",
        "  show_photos(pannel_number) # TODO -> in one line\n",
        "  photo_choice:int = int(input(\"Chose a photo (number, starts with 0)\"))\n",
        "  if photo_choice < 0 or photo_choice >= len(panels):\n",
        "    print(\"Wrong index, first ilustraton is taken.\")\n",
        "    final_ilustrations.append(photos[0])\n",
        "  else:\n",
        "    final_ilustrations.append(photos[photo_choice])\n",
        "    print(\"Ilustration added succesfully!\")\n",
        "\n",
        "\n",
        "final_folder: str = save_folder + '/final'\n",
        "if not os.path.exists(final_folder):\n",
        "  os.mkdir(final_folder)\n",
        "for i, ilustration in enumerate(final_ilustrations):\n",
        "  save_path = save_folder + f'/final/photo{i}.png'\n",
        "  ilustration.save(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y9tbSovpgEI"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT -> HERE USER NEEDS TO SPECIFY DIRECTORY IN ORDER TO CORRECT SAVE/READ PHOTOS\n",
        "import math\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import display\n",
        "\n",
        "FOLDER_TITLE: str = \"Olaf_story2\"\n",
        "save_folder: str = f'/content/drive/MyDrive/{FOLDER_TITLE}'\n",
        "\n",
        "\n",
        "\n",
        "NUM_OF_PHOTOS: int = 4\n",
        "final_folder: str = save_folder + '/final'\n",
        "\n",
        "\n",
        "def display_comic():\n",
        "  row_num: int = 3\n",
        "  m: int = len(os.listdir(final_folder))\n",
        "  n: int = math.ceil(m / row_num)\n",
        "  fig, axes = plt.subplots(n, row_num, figsize=(8 * n, row_num * 20) ,gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "  row, col = 0, 0\n",
        "\n",
        "  for i, ilustration in enumerate(os.listdir(final_folder)):\n",
        "    if i % 3 == 0 and i != 0:\n",
        "      col += 1\n",
        "      row = 0\n",
        "    elif i == 0:\n",
        "      pass\n",
        "    else:\n",
        "      row += 1\n",
        "    img = mpimg.imread(os.path.join(final_folder, ilustration))\n",
        "    currAxes = axes[col, row]\n",
        "    currAxes.set_title(f\"Pannel {i+1}\")\n",
        "    currAxes.axis('off')\n",
        "    currAxes.imshow(img, cmap='gray')\n",
        "\n",
        "  fig.tight_layout(pad=25.0)\n",
        "  plt.tight_layout(pad=25.0)\n",
        "  display(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90xuAm88JIrl"
      },
      "outputs": [],
      "source": [
        "display_comic()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgVGAbg8im0x"
      },
      "source": [
        "**Connect Images and Story**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5s-qaCuZn1B"
      },
      "outputs": [],
      "source": [
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}